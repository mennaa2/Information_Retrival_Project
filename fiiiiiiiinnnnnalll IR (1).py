# -*- coding: utf-8 -*-
"""U.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cSk-dX0sYunyCUOIFHFqPMVjoTLQFccS
"""

!pip install biopython
import csv
import json
import time
from Bio import Entrez, Medline
import os


Entrez.email = "engmennaa5@gmail.com"


DISEASE_LABEL = "cancer"
QUERY = "cancer[Title/Abstract]"
MAX_ABSTRACTS = 1000
DATE_FILTER = "2018:2025[dp]"  # تاريخ النشر من 2018 إلى 2025
RAW_DATA_DIR = "data/raw"

# إنشاء المجلد لو مش موجود
os.makedirs(RAW_DATA_DIR, exist_ok=True)

def search_pubmed_ids(query, max_results):
    full_query = f"{query} AND {DATE_FILTER}"
    handle = Entrez.esearch(db="pubmed", term=full_query, retmax=max_results)
    record = Entrez.read(handle)
    handle.close()
    return record["IdList"]


def fetch_abstracts(id_list):
    abstracts = []
    BATCH_SIZE = 50  # batches to avoid overload

    for start in range(0, len(id_list), BATCH_SIZE):
        batch_ids = id_list[start:start + BATCH_SIZE]
        ids_str = ",".join(batch_ids)

        fetch_handle = Entrez.efetch(db="pubmed", id=ids_str, rettype="medline", retmode="text")
        records = Medline.parse(fetch_handle)

        for rec in records:
            abstract_text = rec.get("AB", "").strip()
            if abstract_text:
                abstracts.append(abstract_text)

        fetch_handle.close()
        time.sleep(0.4)  # NCBI polite usage

    return abstracts


print(f"Searching PubMed for {DISEASE_LABEL} abstracts...")
ids = search_pubmed_ids(QUERY, MAX_ABSTRACTS)
print(f"Found {len(ids)} PubMed IDs")

abstracts = fetch_abstracts(ids)
print(f"Fetched {len(abstracts)} abstracts")

# Prepare rows
rows = [{"label": DISEASE_LABEL, "abstract": a} for a in abstracts]

csv_file = os.path.join(RAW_DATA_DIR, "pubmed_cancer.csv")
with open(csv_file, "w", newline="", encoding="utf-8") as f:
    writer = csv.DictWriter(f, fieldnames=["label", "abstract"])
    writer.writeheader()
    writer.writerows(rows)

json_file = os.path.join(RAW_DATA_DIR, "pubmed_cancer.json")
with open(json_file, "w", encoding="utf-8") as f:
    json.dump(rows, f, ensure_ascii=False, indent=2)

print(f"Saved CSV: {csv_file}")
print(f"Saved JSON: {json_file}")
print("Done.")

import os
import pandas as pd
import nltk
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
import string

# 1) Download NLTK resources
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('punkt_tab') # Added to resolve LookupError

stop_words = set(stopwords.words('english'))
stemmer = PorterStemmer()

def preprocess_text(text: str) -> str:
    # Lowercase
    text = text.lower()
    # Remove punctuation
    text = text.translate(str.maketrans("", "", string.punctuation))
    # Tokenization
    tokens = nltk.word_tokenize(text)
    # Remove stopwords
    tokens = [t for t in tokens if t not in stop_words]
    # Stemming
    tokens = [stemmer.stem(t) for t in tokens]
    # Join back to string
    return " ".join(tokens)

RAW_DATA_FILE = "data/raw/pubmed_cancer.csv"
PROCESSED_DIR = "data/processed"
PROCESSED_FILE = os.path.join(PROCESSED_DIR, "pubmed_cancer_processed.csv")

os.makedirs(PROCESSED_DIR, exist_ok=True)

df = pd.read_csv(RAW_DATA_FILE)

df['processed_abstract'] = df['abstract'].astype(str).apply(preprocess_text)

df.to_csv(PROCESSED_FILE, index=False)
print(f"Processed data saved to: {PROCESSED_FILE}")

import os
import re
import sys
import time
from collections import defaultdict
from typing import Dict, Set, List, Tuple, Optional

import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# Paths (adjust to your files)
RAW_CSV = "data/raw/pubmed_cancer.csv"
PROCESSED_CSV = "data/processed/pubmed_cancer_processed.csv"

# Preprocessing
STOPWORDS = {
    "a", "an", "the", "and", "or", "in", "on", "at", "to", "for", "of", "with", "without",
    "is", "are", "was", "were", "be", "been", "being", "as", "by", "that", "this", "these",
    "those", "it", "its", "from", "into", "than", "may", "might", "can", "could", "should",
    "would", "also", "such", "while", "within", "between", "over", "under", "per", "using",
    "use", "used", "study", "studies", "results", "result", "background", "conclusion",
    "objective", "methods", "method", "observed", "significant"
}

TOKEN_RE = re.compile(r"\b[a-zA-Z0-9\-]+\b")

def tokenize(text: str) -> List[str]:
    return [t.lower() for t in TOKEN_RE.findall(str(text))]

def preprocess(text: str) -> str:
    tokens = [t for t in tokenize(text) if t not in STOPWORDS]
    return " ".join(tokens)

# Load documents
def load_documents() -> Dict[str, str]:
    df = None # Initialize df
    text_column_to_use = None

    if os.path.exists(PROCESSED_CSV):
        df = pd.read_csv(PROCESSED_CSV)
        print(f"Loaded processed CSV: {PROCESSED_CSV}")
        # Check for 'processed_abstract' as created by the previous preprocessing cell
        if 'processed_abstract' in df.columns:
            text_column_to_use = 'processed_abstract'
        elif 'abstract' in df.columns:
            # If 'processed_abstract' is missing but 'abstract' is present, preprocess it
            print("Warning: 'processed_abstract' not found, reprocessing 'abstract' column.")
            df['processed_abstract'] = df['abstract'].astype(str).apply(preprocess)
            text_column_to_use = 'processed_abstract'
        else:
            print("ERROR: Neither 'processed_abstract' nor 'abstract' column found in processed CSV.")
            sys.exit(1)

    elif os.path.exists(RAW_CSV):
        df = pd.read_csv(RAW_CSV)
        print(f"Loaded raw CSV: {RAW_CSV}")
        # Create 'processed_abstract' column for consistency
        df['processed_abstract'] = df['abstract'].astype(str).apply(preprocess)
        os.makedirs("data/processed", exist_ok=True)
        df.to_csv(PROCESSED_CSV, index=False, encoding='utf-8')
        print(f"Saved processed CSV: {PROCESSED_CSV}")
        text_column_to_use = 'processed_abstract'
    else:
        print("No CSV found!")
        sys.exit(1)

    if df is None or text_column_to_use is None: # Should not happen with sys.exit, but for safety
        print("Error: DataFrame or text column not properly initialized.")
        sys.exit(1)

    if 'doc_id' not in df.columns:
        df['doc_id'] = df.index.astype(str)

    documents = dict(zip(df['doc_id'], df[text_column_to_use]))
    return documents

# Inverted Index
def build_inverted_index(documents: Dict[str, str]) -> Dict[str, Set[str]]:
    inv = defaultdict(set)
    for doc_id, text in documents.items():
        for term in set(tokenize(text)):
            inv[term].add(doc_id)
    return dict(inv)

# Boolean Retrieval
def term_docs(term: str, inv_index: Dict[str, Set[str]]) -> Set[str]:
    return inv_index.get(term.lower(), set())

def boolean_and(terms: List[str], inv_index: Dict[str, Set[str]], all_docs: Set[str]) -> Set[str]:
    res = all_docs.copy()
    for t in terms:
        res &= term_docs(t, inv_index)
    return res

def boolean_or(terms: List[str], inv_index: Dict[str, Set[str]]) -> Set[str]:
    res = set()
    for t in terms:
        res |= term_docs(t, inv_index)
    return res

def boolean_not(terms: List[str], inv_index: Dict[str, Set[str]], all_docs: Set[str]) -> Set[str]:
    res = all_docs.copy()
    for t in terms:
        res -= term_docs(t, inv_index)
    return res

# TF-IDF Vector Space
class TfidfRanker:
    def __init__(self, documents: Dict[str, str]):
        self.doc_ids = list(documents.keys())
        self.texts = [documents[i] for i in self.doc_ids]
        self.vectorizer = TfidfVectorizer(tokenizer=tokenize, preprocessor=None, lowercase=False)
        self.matrix = self.vectorizer.fit_transform(self.texts)

    def rank(self, query: str, top_k: int = 10) -> List[Tuple[str, float]]:
        qvec = self.vectorizer.transform([query])
        scores = (self.matrix @ qvec.T).toarray().flatten()
        order = np.argsort(-scores)
        out = []
        for idx in order:
            if scores[idx] <= 0:
                continue
            out.append((self.doc_ids[idx], float(scores[idx])))
            if len(out) >= top_k:
                break
        return out

# Snippets
def make_snippet(text: str, query_terms: List[str], window: int = 6) -> str:
    toks = tokenize(text)
    qset = {t.lower() for t in query_terms}
    for i, tok in enumerate(toks):
        if tok in qset:
            start = max(0, i - window)
            end = min(len(toks), i + window + 1)
            chunk = toks[start:end]
            chunk[i - start] = chunk[i - start].upper()
            return "... " + " ".join(chunk) + " ..."
    return text[:200] + "..." if len(text) > 200 else text

# Metrics (Precision, Recall, F1, AP, MAP)
def precision_at_k(retrieved: List[str], relevant: Set[str], k: int) -> float:
    retrieved_k = retrieved[:k]
    if k == 0:
        return 0.0
    return sum(1 for d in retrieved_k if d in relevant) / k

def recall_at_k(retrieved: List[str], relevant: Set[str], k: int) -> float:
    retrieved_k = retrieved[:k]
    if not relevant:
        return 0.0
    return sum(1 for d in retrieved_k if d in relevant) / len(relevant)

def f1_score(p: float, r: float) -> float:
    return 2*p*r/(p+r) if (p+r)>0 else 0.0

def average_precision(retrieved: List[str], relevant: Set[str]) -> float:
    precisions = []
    num_rel = 0
    for i, doc in enumerate(retrieved, start=1):
        if doc in relevant:
            num_rel += 1
            precisions.append(num_rel / i)
    return sum(precisions) / len(relevant) if relevant else 0.0

def mean_average_precision(results: Dict[str, List[str]], qrels: Dict[str, Set[str]]) -> float:
    aps = [average_precision(results[q], qrels.get(q, set())) for q in results]
    return np.mean(aps) if aps else 0.0

# CLI / Demo
def main():
    documents = load_documents()
    all_docs = set(documents.keys())

    print("PUBMED CANCER IR SYSTEM (Boolean + TF-IDF)")
    inv_index = build_inverted_index(documents)
    ranker = TfidfRanker(documents)

    print(f"Indexed {len(inv_index)} terms in {len(documents)} documents.\n")
    print("Type 'exit' to quit.\n")

    while True:
        query = input("Query> ").strip()
        if query.lower() == "exit":
            break
        if not query:
            continue

        terms = [t for t in query.split() if t]

        # Boolean
        print("\n--- Boolean (AND) ---")
        res_and = boolean_and(terms, inv_index, all_docs)
        for doc_id in sorted(res_and)[:10]:
            print(f"[{doc_id}] {make_snippet(documents[doc_id], terms)}")

        print("\n--- Boolean (OR) ---")
        res_or = boolean_or(terms, inv_index)
        for doc_id in sorted(res_or)[:10]:
            print(f"[{doc_id}] {make_snippet(documents[doc_id], terms)}")

        print("\n--- Boolean (NOT) ---")
        res_not = boolean_not(terms, inv_index, all_docs)
        for doc_id in sorted(res_not)[:10]:
            print(f"[{doc_id}] {make_snippet(documents[doc_id], terms)}")

        # TF-IDF ranking
        print("\n--- TF-IDF Ranking (Top 10) ---")
        ranked = ranker.rank(query, top_k=10)
        for doc_id, score in ranked:
            print(f"[{doc_id}] score={score:.4f} {make_snippet(documents[doc_id], terms)}")

        print("\n" + "-"*50 + "\n")

if __name__ == "__main__":
    main()

import json
import math
import nltk
from typing import List, Set, Dict
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
import os # Added import
import pandas as pd # Added import
from collections import defaultdict # Added import

nltk.download("punkt")
nltk.download("stopwords")

# --------------------------------------------------
# Text Preprocessing
# --------------------------------------------------
stop_words = set(stopwords.words("english"))
stemmer = PorterStemmer()

def preprocess_text(text: str) -> List[str]:
    """
    Tokenize text, remove stopwords, and apply stemming.
    """
    tokens = nltk.word_tokenize(text.lower())
    tokens = [token for token in tokens if token.isalnum()]
    tokens = [token for token in tokens if token not in stop_words]
    tokens = [stemmer.stem(token) for token in tokens]
    return tokens

# --------------------------------------------------
# Snippet Generation
# --------------------------------------------------
def generate_snippet(document_text: str, query_terms: List[str]) -> str:
    """
    Generate a short snippet around the first occurrence
    of any query term.
    """
    document_text_lower = document_text.lower()

    for term in query_terms:
        if term in document_text_lower:
            start_index = document_text_lower.find(term)
            context_start = max(0, start_index - 50)
            context_end = min(len(document_text), start_index + 100)
            snippet = document_text[context_start:context_end].strip()
            return "..." + snippet + "..."

    return document_text[:150] + "..."

# --------------------------------------------------
# Ranked Retrieval using TF-IDF
# --------------------------------------------------
def rank_documents(
    query: str,
    inverted_index: Dict[str, Dict[str, int]],
    documents: Dict[str, Dict],
    top_k: int = 30
):
    """
    Rank documents using the Vector Space Model with TF-IDF.
    Returns a list of (document_id, score, snippet).
    """
    query_terms = preprocess_text(query)
    document_scores = {}
    total_documents = len(documents)

    for term in query_terms:
        if term not in inverted_index:
            continue

        document_frequency = len(inverted_index[term])
        inverse_document_frequency = (
            math.log10(total_documents / document_frequency)
            if document_frequency > 0 else 0
        )

        for document_id, term_frequency in inverted_index[term].items():
            if document_id in documents:
                document_scores[document_id] = (
                    document_scores.get(document_id, 0)
                    + term_frequency * inverse_document_frequency
                )

    ranked_documents = sorted(
        document_scores.items(),
        key=lambda item: item[1],
        reverse=True
    )

    results = []
    for document_id, score in ranked_documents[:top_k]:
        document_text = documents[document_id].get(
            "text", "Document text not found."
        )
        snippet = generate_snippet(document_text, query_terms)
        results.append((document_id, score, snippet))

    return results

# --------------------------------------------------
# Evaluation Metrics
# --------------------------------------------------
def precision_at_k(
    retrieved_documents: List[str],
    relevant_documents: Set[str],
    k: int
) -> float:
    retrieved_at_k = retrieved_documents[:k]
    relevant_retrieved = sum(
        1 for doc_id in retrieved_at_k if doc_id in relevant_documents
    )
    return relevant_retrieved / k if k > 0 else 0.0

def recall_at_k(
    retrieved_documents: List[str],
    relevant_documents: Set[str],
    k: int
) -> float:
    retrieved_at_k = retrieved_documents[:k]
    relevant_retrieved = sum(
        1 for doc_id in retrieved_at_k if doc_id in relevant_documents
    )
    return (
        relevant_retrieved / len(relevant_documents)
        if relevant_documents else 0.0
    )

def f1_measure(precision: float, recall: float) -> float:
    if precision + recall == 0:  # Fix for ZeroDivisionError
        return 0.0
    return 2 * precision * recall / (precision + recall)

def average_precision(
    retrieved_documents: List[str],
    relevant_documents: Set[str]
) -> float:
    precision_values = []
    relevant_count = 0

    for rank, document_id in enumerate(retrieved_documents, start=1):
        if document_id in relevant_documents:
            relevant_count += 1
            precision_values.append(relevant_count / rank)

    return (
        sum(precision_values) / len(relevant_documents)
        if relevant_documents else 0.0
    )

def mean_average_precision(
    all_results: Dict[str, List[str]],
    relevance_judgments: Dict[str, Set[str]]
) -> float:
    average_precisions = []

    for query, retrieved_documents in all_results.items():
        relevant_documents = relevance_judgments.get(query, set())
        average_precisions.append(
            average_precision(retrieved_documents, relevant_documents)
        )

    return (
        sum(average_precisions) / len(average_precisions)
        if average_precisions else 0.0
    )

# --------------------------------------------------
# System Evaluation
# --------------------------------------------------
def evaluate_system(
    results: Dict[str, List[str]],
    relevance_judgments: Dict[str, Set[str]],
    k: int = 30
):
    evaluation_results = {}

    for query, retrieved_documents in results.items():
        relevant_documents = relevance_judgments.get(query, set())

        precision_value = precision_at_k(
            retrieved_documents, relevant_documents, k
        )
        recall_value = recall_at_k(
            retrieved_documents, relevant_documents, k
        )
        f1_value = f1_measure(precision_value, recall_value)
        average_precision_value = average_precision(
            retrieved_documents, relevant_documents
        )

        evaluation_results[query] = {
            "Precision at K": precision_value,
            "Recall at K": recall_value,
            "F1 Measure at K": f1_value,
            "Average Precision": average_precision_value
        }

    return evaluation_results

def print_evaluation_report(
    results: Dict[str, List[str]],
    relevance_judgments: Dict[str, Set[str]],
    k: int = 30
):
    evaluation = evaluate_system(results, relevance_judgments, k)
    mean_average_precision_value = mean_average_precision(
        results, relevance_judgments
    )

    print("=" * 70)
    print("Information Retrieval System Evaluation Report")
    print("=" * 70)

    for query, metrics in evaluation.items():
        print(f"\nQuery: {query}")
        for metric_name, value in metrics.items():
            print(f"  {metric_name}: {value:.4f}")

    print("\nOverall System Performance")
    print(f"  Mean Average Precision: {mean_average_precision_value:.4f}")
    print("=" * 70)

# --------------------------------------------------
# Main Execution
# --------------------------------------------------
if __name__ == "__main__":

    PROCESSED_CSV = "data/processed/pubmed_cancer_processed.csv"
    CLEANED_DOCUMENTS_JSON = "cleaned_documents.json"
    INVERTED_INDEX_JSON = "inverted_index.json"

    documents = {}
    inverted_index = {}

    # Check if cleaned_documents.json and inverted_index.json exist
    if not os.path.exists(CLEANED_DOCUMENTS_JSON) or not os.path.exists(INVERTED_INDEX_JSON):
        print("Generating cleaned_documents.json and inverted_index.json...")
        if not os.path.exists(PROCESSED_CSV):
            print(f"Error: Processed CSV file not found at {PROCESSED_CSV}. Please run previous cells.")
        else:
            df = pd.read_csv(PROCESSED_CSV)

            # Create documents dictionary
            documents_list_for_json = []
            for idx, row in df.iterrows():
                # Use 'doc_id' if available from previous processing, otherwise use index
                doc_id = str(row.get('doc_id', idx))
                documents_list_for_json.append({
                    "pmid": doc_id,
                    "text": row["processed_abstract"]
                })

            documents = {doc["pmid"]: doc for doc in documents_list_for_json}

            # Build inverted index with term frequencies
            temp_inverted_index = defaultdict(lambda: defaultdict(int))
            for doc_id, doc_data in documents.items():
                text = doc_data["text"]
                tokens = preprocess_text(text)
                for token in tokens:
                    temp_inverted_index[token][doc_id] += 1
            inverted_index = {term: dict(docs) for term, docs in temp_inverted_index.items()}

            # Save to JSON files
            with open(CLEANED_DOCUMENTS_JSON, "w", encoding="utf-8") as file:
                json.dump(documents_list_for_json, file, ensure_ascii=False, indent=2)
            print(f"Saved cleaned documents to {CLEANED_DOCUMENTS_JSON}")

            with open(INVERTED_INDEX_JSON, "w", encoding="utf-8") as file:
                json.dump(inverted_index, file, ensure_ascii=False, indent=2)
            print(f"Saved inverted index to {INVERTED_INDEX_JSON}")
    else:
        print("Loading existing cleaned_documents.json and inverted_index.json...")
        with open(CLEANED_DOCUMENTS_JSON, "r", encoding="utf-8") as file:
            documents_list = json.load(file)
        documents = {str(doc["pmid"]): doc for doc in documents_list}

        with open(INVERTED_INDEX_JSON, "r", encoding="utf-8") as file:
            inverted_index = json.load(file)
        print("Files loaded successfully.")

    # Updated relevance judgments for cancer data
    relevance_judgments = {
        "cancer": {"580", "594", "750", "523", "541", "729", "596", "317", "205", "551"},
        "breast cancer": {"0", "29", "35", "111", "120", "169", "252", "334", "403", "472"},
        "lung cancer": {"106", "127", "131", "138", "142", "145", "155", "163", "172", "175"},
        "cancer therapy": {"1", "5", "12", "15", "19", "21", "24", "26", "28", "31"},
        "gene mutation": {"3", "4", "7", "11", "14", "17", "20", "22", "23", "25"},
    }

    retrieval_results = {}

    for query in relevance_judgments:
        # Ensure the query terms are preprocessed for snippet generation consistency
        processed_query_terms = preprocess_text(query)
        ranked_results = rank_documents(
            query, inverted_index, documents, top_k=30
        )
        retrieved_document_ids = [
            document_id for document_id, _, _ in ranked_results
        ]
        retrieval_results[query] = retrieved_document_ids

    print_evaluation_report(
        retrieval_results, relevance_judgments, k=30
    )


# ---------- GUI ----------
class IRGui:
    def __init__(self, master, documents, inv_index, ranker):
        self.master = master
        master.title("Information Retrieval Project")

        # ---------- Window Size & Center ----------
        window_width = 900
        window_height = 680
        screen_width = master.winfo_screenwidth()
        screen_height = master.winfo_screenheight()
        x = (screen_width // 2) - (window_width // 2)
        y = (screen_height // 2) - (window_height // 2)
        master.geometry(f"{window_width}x{window_height}+{x}+{y}")
        master.resizable(False, False)

        # ---------- Colors ----------
        BG_COLOR = "#F6C1CC"
        TITLE_COLOR = "#1f3c88"
        BUTTON_COLOR = "#1f3c88"
        BUTTON_TEXT = "#ffffff"
        BOX_BG = "#ffffff"
        LABEL_COLOR = "#1f3c88"
        master.configure(bg=BG_COLOR)

        self.documents = documents
        self.inv_index = inv_index
        self.ranker = ranker
        self.all_docs = set(documents.keys())

        # ---------- Style ----------
        style = ttk.Style()
        style.theme_use("default")
        style.configure(
            "TButton",
            background=BUTTON_COLOR,
            foreground=BUTTON_TEXT,
            font=("Arial", 11, "bold"),
            padding=6
        )
        style.map(
            "TButton",
            background=[("active", "#163172")]
        )
        style.configure(
            "TLabel",
            background=BG_COLOR,
            foreground=LABEL_COLOR,
            font=("Arial", 11)
        )

        # ---------- Title ----------
        title_label = ttk.Label(
            master,
            text="Information Retrieval Project",
            font=("Arial", 20, "bold"),
            foreground=TITLE_COLOR
        )
        title_label.pack(pady=20)

        # ---------- Query Section ----------
        query_frame = tk.Frame(master, bg=BG_COLOR)
        query_frame.pack(pady=10)

        ttk.Label(query_frame, text="Search Query:").grid(row=0, column=0, padx=5)
        self.query_entry = ttk.Entry(query_frame, width=50)
        self.query_entry.grid(row=0, column=1, padx=10)

        search_btn = ttk.Button(query_frame, text="Search", command=self.run_search)
        search_btn.grid(row=0, column=2, padx=5)

        # ---------- Clear Button ----------
        clear_btn = ttk.Button(query_frame, text="Clear", command=self.clear)
        clear_btn.grid(row=0, column=3, padx=5)

        # ---------- Boolean Results ----------
        ttk.Label(
            master,
            text="Boolean AND Results",
            font=("Arial", 13, "bold")
        ).pack(pady=5)

        self.bool_box = scrolledtext.ScrolledText(
            master,
            width=100,
            height=10,
            bg=BOX_BG,
            fg="#000000",
            wrap=tk.WORD
        )
        self.bool_box.pack(padx=15, pady=5)

        # ---------- TF-IDF Results ----------
        ttk.Label(
            master,
            text="TF-IDF Ranked Results",
            font=("Arial", 13, "bold")
        ).pack(pady=5)

        self.tfidf_box = scrolledtext.ScrolledText(
            master,
            width=100,
            height=10,
            bg=BOX_BG,
            fg="#000000",
            wrap=tk.WORD
        )
        self.tfidf_box.pack(padx=15, pady=5)

    # ---------- Search ----------
    def run_search(self):
        query_text = self.query_entry.get().strip()
        if not query_text:
            return
        threading.Thread(target=self.search_and_display, args=(query_text,)).start()

    def search_and_display(self, query_text):
        terms = query_text.split()

        self.bool_box.delete("1.0", tk.END)
        self.tfidf_box.delete("1.0", tk.END)

        # Boolean AND
        bool_res = boolean_and(terms, self.inv_index, self.all_docs)
        if not bool_res:
            self.bool_box.insert(tk.END, "No Boolean results found.\n")
        else:
            for doc_id in list(bool_res)[:20]:
                snippet = make_snippet(self.documents[doc_id], terms)
                self.bool_box.insert(tk.END, f"[{doc_id}] {snippet}\n\n")

        # TF-IDF Ranking
        ranked = self.ranker.rank(query_text, top_k=20)
        if not ranked:
            self.tfidf_box.insert(tk.END, "No TF-IDF results found.\n")
        else:
            for doc_id, score in ranked:
                snippet = make_snippet(self.documents[doc_id], terms)
                self.tfidf_box.insert(
                    tk.END,
                    f"[{doc_id}]  Score: {score:.4f}\n{snippet}\n\n"
                )

    # ---------- Clear ----------
    def clear(self):
        self.query_entry.delete(0, tk.END)
        self.bool_box.delete("1.0", tk.END)
        self.tfidf_box.delete("1.0", tk.END)
        
# ---------- GUI ----------
class IRGui:
    def __init__(self, master, documents, inv_index, ranker):
        self.master = master
        master.title("Information Retrieval Project")

        # ---------- Window Size & Center ----------
        window_width = 900
        window_height = 680
        screen_width = master.winfo_screenwidth()
        screen_height = master.winfo_screenheight()
        x = (screen_width // 2) - (window_width // 2)
        y = (screen_height // 2) - (window_height // 2)
        master.geometry(f"{window_width}x{window_height}+{x}+{y}")
        master.resizable(False, False)

        # ---------- Colors ----------
        BG_COLOR = "#F6C1CC"
        TITLE_COLOR = "#1f3c88"
        BUTTON_COLOR = "#1f3c88"
        BUTTON_TEXT = "#ffffff"
        BOX_BG = "#ffffff"
        LABEL_COLOR = "#1f3c88"
        master.configure(bg=BG_COLOR)

        self.documents = documents
        self.inv_index = inv_index
        self.ranker = ranker
        self.all_docs = set(documents.keys())

        # ---------- Style ----------
        style = ttk.Style()
        style.theme_use("default")
        style.configure(
            "TButton",
            background=BUTTON_COLOR,
            foreground=BUTTON_TEXT,
            font=("Arial", 11, "bold"),
            padding=6
        )
        style.map(
            "TButton",
            background=[("active", "#163172")]
        )
        style.configure(
            "TLabel",
            background=BG_COLOR,
            foreground=LABEL_COLOR,
            font=("Arial", 11)
        )

        # ---------- Title ----------
        title_label = ttk.Label(
            master,
            text="Information Retrieval Project",
            font=("Arial", 20, "bold"),
            foreground=TITLE_COLOR
        )
        title_label.pack(pady=20)

        # ---------- Query Section ----------
        query_frame = tk.Frame(master, bg=BG_COLOR)
        query_frame.pack(pady=10)

        ttk.Label(query_frame, text="Search Query:").grid(row=0, column=0, padx=5)
        self.query_entry = ttk.Entry(query_frame, width=50)
        self.query_entry.grid(row=0, column=1, padx=10)

        search_btn = ttk.Button(query_frame, text="Search", command=self.run_search)
        search_btn.grid(row=0, column=2, padx=5)

        # ---------- Clear Button ----------
        clear_btn = ttk.Button(query_frame, text="Clear", command=self.clear)
        clear_btn.grid(row=0, column=3, padx=5)

        # ---------- Boolean Results ----------
        ttk.Label(
            master,
            text="Boolean AND Results",
            font=("Arial", 13, "bold")
        ).pack(pady=5)

        self.bool_box = scrolledtext.ScrolledText(
            master,
            width=100,
            height=10,
            bg=BOX_BG,
            fg="#000000",
            wrap=tk.WORD
        )
        self.bool_box.pack(padx=15, pady=5)

        # ---------- TF-IDF Results ----------
        ttk.Label(
            master,
            text="TF-IDF Ranked Results",
            font=("Arial", 13, "bold")
        ).pack(pady=5)

        self.tfidf_box = scrolledtext.ScrolledText(
            master,
            width=100,
            height=10,
            bg=BOX_BG,
            fg="#000000",
            wrap=tk.WORD
        )
        self.tfidf_box.pack(padx=15, pady=5)

    # ---------- Search ----------
    def run_search(self):
        query_text = self.query_entry.get().strip()
        if not query_text:
            return
        threading.Thread(target=self.search_and_display, args=(query_text,)).start()

    def search_and_display(self, query_text):
        terms = query_text.split()

        self.bool_box.delete("1.0", tk.END)
        self.tfidf_box.delete("1.0", tk.END)

        # Boolean AND
        bool_res = boolean_and(terms, self.inv_index, self.all_docs)
        if not bool_res:
            self.bool_box.insert(tk.END, "No Boolean results found.\n")
        else:
            for doc_id in list(bool_res)[:20]:
                snippet = make_snippet(self.documents[doc_id], terms)
                self.bool_box.insert(tk.END, f"[{doc_id}] {snippet}\n\n")

        # TF-IDF Ranking
        ranked = self.ranker.rank(query_text, top_k=20)
        if not ranked:
            self.tfidf_box.insert(tk.END, "No TF-IDF results found.\n")
        else:
            for doc_id, score in ranked:
                snippet = make_snippet(self.documents[doc_id], terms)
                self.tfidf_box.insert(
                    tk.END,
                    f"[{doc_id}]  Score: {score:.4f}\n{snippet}\n\n"
                )

    # ---------- Clear ----------
    def clear(self):
        self.query_entry.delete(0, tk.END)
        self.bool_box.delete("1.0", tk.END)
        self.tfidf_box.delete("1.0", tk.END)


# ---------- Start Application ----------
# ---------- Start Application ----------
documents = load_documents()  # only one value returned
inv_index = build_inverted_index(documents)
ranker = TfidfRanker(documents)

root = tk.Tk()
app = IRGui(root, documents, inv_index, ranker)
root.mainloop()





